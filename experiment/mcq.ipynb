{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9c51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f5a2b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import pandas as pd \n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4b37db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ac968e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67c1ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv('OPENAI_API_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec4bbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=KEY,model_name = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57e60f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f84e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1321604a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b524e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"sk-proj-vGYb2GIjM86mxx0je9xwho8CJH6pqCd1diUnA6Ui\n"
     ]
    }
   ],
   "source": [
    "print(KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f601289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000021530F7F680>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021530DB0B90>, root_client=<openai.OpenAI object at 0x000002152DB45C40>, root_async_client=<openai.AsyncOpenAI object at 0x0000021530F7D310>, model_kwargs={})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2002178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "import PyPDF2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "62fe2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"it is the format of the quiz\"\n",
    "\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice quesrion\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice quesrion\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice quesrion\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fb398465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"it is a template for the generation of the quiz. the whole quiz qns are generated based on the below template\"\n",
    "\"this is what we pass to our gpt model\"\n",
    "\n",
    "TEMPLATE=\"\"\"Text:{text}\n",
    "    You are an MCQ maker. Given the above text, it is your job to \\\n",
    "    create a quiz of {number} multiple choice questions for {subject} studenrs is {tone} tone.\n",
    "    make sure the question are not repeated and check all the questions to be conforming the text as well.\n",
    "    Make sure tto format your response like RESPONSE_JSON below nd use it as a guide. \\\n",
    "    Ensure to make {number} MCQs\n",
    "    ### RESPONSE_JSON\n",
    "    {response_json}\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe3175c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the input variables are from the user side'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"here we define the prompt template\"\n",
    "\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "\"the input variables are from the user side\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c22c4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"it is a chain to to combine the llm and the prompt\"\n",
    "\n",
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d6096543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"after analyzing the quiz for the prompt we need the correct answer.\n",
    " for this i have created another template callled templete2\"\"\"\n",
    "\n",
    "TEMPLATE2=\"\"\"\n",
    "You are an expert English grammarian and writer given at multiple choice quiz per {subject} students. \\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz.\n",
    "Only use at maximum of 50 words per quiz. \n",
    "The quiz is not per with the cognitive and analytical abilities of the student,\\\n",
    "Compare to quiz, questions which need to be changed and change the tool such that it perfectly fits the student abilities. \n",
    "Quiz_MCQ:\n",
    "{quiz}\n",
    "\n",
    "check for an expert English writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd8ed226",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d09a0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d51dba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"now we have two chains here , we combine those two chain with the help of the sequential chain method.\"\n",
    "\n",
    "\n",
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\",\"number\", \"subject\",\"tone\", \"response_json\"], \n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a5344c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r before the path is indicates the absolute path '"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"we need the data for generating the quiz. so we created a data.txt file in which i had entered the ai wikipedia data\"\n",
    "\n",
    "file_path = r\"C:\\Users\\MOHAMMED FEROZ\\mcqgenerator\\data.txt\"\n",
    "\n",
    "\"\"\"r before the path is indicates the absolute path \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6aee7e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MOHAMMED FEROZ\\\\mcqgenerator\\\\data.txt'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a6fef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"to open and read the file\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXTS = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0cec018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI\" redirects here. For other uses, see AI (disambiguation) and Artificial intelligence (disambiguation).\n",
      "Part of a series on\n",
      "Artificial intelligence (AI)\n",
      "\n",
      "\n",
      "Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.\n",
      "\n",
      "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3]\n",
      "\n",
      "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as humans.[5]\n",
      "\n",
      "Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, the period of rapid progress marked by advanced generative AI became known as the AI boom. Generative AI and its ability to create and modify content exposed several unintended consequences and harms in the present and raised ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n"
     ]
    }
   ],
   "source": [
    "print(TEXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "045e98d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice quesrion\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice quesrion\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice quesrion\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"in the above we given the format of the quiz which is in the dictionary format. now we convert it into the json format\"\n",
    "\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "16554662",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 5\n",
    "SUBJECT = \"artificial intelligence\"\n",
    "TONE = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83219727",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = generate_evaluate_chain({\n",
    "        \"text\": TEXTS,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6baeb6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:0\n",
      "Ptompt Tokens:0\n",
      "Completion Tokens:0\n",
      "Total Cost:0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Ptompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the token values will be shown once we give the premium OPenAI API'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"the token values will be shown once we give the premium OPenAI API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response\n",
    "\n",
    "\"not running because of the API access\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b61dbbf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m quiz=response.get(\u001b[33m\"\u001b[39m\u001b[33mquiz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mthe error is because of the API access\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "quiz=response.get(\"quiz\")\n",
    "\n",
    "\"the error is because of the API access\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28fa540d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quiz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m json.loads(quiz)\n",
      "\u001b[31mNameError\u001b[39m: name 'quiz' is not defined"
     ]
    }
   ],
   "source": [
    "json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".json(\n",
    "        [\n",
    "        f\"{option}: {option_value}\"\n",
    "        for option, option_value in value[\"options\"].items()\n",
    "        \n",
    "        ]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\":mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef959c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"artificial intelligence\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce0513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05_23_2025_10_47_14.log\n"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "LOF_FILE=f\"{datetime.now().strftime('%m_%d_%Y_%H_%M_%S')}.log\"\n",
    "\n",
    "print(LOF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979cd00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
